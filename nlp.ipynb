{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2060 (UUID: GPU-1191f81c-7fba-75e4-915b-9616e90b1b53)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-02-06 18:24:30--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10246 (10K) [text/plain]\n",
      "Saving to: 'helper_functions.py'\n",
      "\n",
      "     0K ..........                                            100% 14.7M=0.001s\n",
      "\n",
      "2022-02-06 18:24:30 (14.7 MB/s) - 'helper_functions.py' saved [10246/10246]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-02-07 09:20:52--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.13.112, 172.217.13.144, 172.217.13.176, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.13.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 607343 (593K) [application/zip]\n",
      "Saving to: 'nlp_getting_started.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  8% 19.6M 0s\n",
      "    50K .......... .......... .......... .......... .......... 16% 20.0M 0s\n",
      "   100K .......... .......... .......... .......... .......... 25% 19.2M 0s\n",
      "   150K .......... .......... .......... .......... .......... 33% 19.8M 0s\n",
      "   200K .......... .......... .......... .......... .......... 42% 19.1M 0s\n",
      "   250K .......... .......... .......... .......... .......... 50% 19.3M 0s\n",
      "   300K .......... .......... .......... .......... .......... 59% 18.3M 0s\n",
      "   350K .......... .......... .......... .......... .......... 67% 20.2M 0s\n",
      "   400K .......... .......... .......... .......... .......... 75% 18.9M 0s\n",
      "   450K .......... .......... .......... .......... .......... 84% 19.8M 0s\n",
      "   500K .......... .......... .......... .......... .......... 92% 18.0M 0s\n",
      "   550K .......... .......... .......... .......... ...       100% 22.5M=0.03s\n",
      "\n",
      "2022-02-07 09:20:52 (19.5 MB/s) - 'nlp_getting_started.zip' saved [607343/607343]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df_shuffled['text'].to_numpy(), train_df_shuffled['target'].to_numpy(), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6851,), (762,), (6851,), (762,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use tokenization or Embeddings\n",
    "\n",
    "# - create your own embedding\n",
    "\n",
    "# - re-use a pre-learned embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing layer for tokenization\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None, # words in the vocabulary\n",
    "    standardize='lower_and_strip_punctuation', # how to process text\n",
    "    split='whitespace', # how to split tokens\n",
    "    ngrams=None, # create groups of n words\n",
    "    output_mode='int', # how to map tokens to numbers\n",
    "    output_sequence_length=None # how long should the output sequence of tokens be?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = \"There's a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence 'someone: mentions gansey on fire\n",
      "me busting through the brick walls of seven different buildings:'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 475, 2050,    1,   11,   42,   31,    1,  295,    2, 6067, 3266,\n",
       "           6, 1766, 1215,   95]], dtype=int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random_sentence = random.choice(X_train)\n",
    "print(f\"Original sentence '{random_sentence}'.\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab 10000\n",
      "Top 5 most common words : ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words : ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "print(f\"Number of words in vocab {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words : {top_5_words}\")\n",
    "print(f\"Bottom 5 least common words : {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Embedding using an Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    embeddings_initializer='uniform',\n",
    "    input_length=max_length,\n",
    "    name='embedding_1',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text : 'With a sinking music video tv career Brooke Hogan should be THANKING her Dad for the free publicity...although I doubt it will help her.'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.04978979, -0.0019431 , -0.00039934, ..., -0.01621551,\n",
       "          0.03926425,  0.02467387],\n",
       "        [-0.04284013, -0.01489798, -0.0159496 , ..., -0.01166106,\n",
       "          0.03061062,  0.01972148],\n",
       "        [ 0.0386066 ,  0.01791922,  0.04897166, ...,  0.02531831,\n",
       "         -0.00777938,  0.04759762],\n",
       "        ...,\n",
       "        [ 0.00528262, -0.04030708,  0.04332492, ...,  0.00316782,\n",
       "          0.03644954, -0.00621504],\n",
       "        [-0.04111345, -0.03443157, -0.00189682, ..., -0.01965671,\n",
       "          0.04853431, -0.01313479],\n",
       "        [-0.03508195,  0.01448471,  0.00513798, ...,  0.04485155,\n",
       "          0.03976364, -0.03543619]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(X_train)\n",
    "print(f\"Original text : '{random_sentence}'.\")\n",
    "\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 0.04978979, -0.0019431 , -0.00039934,  0.00179777,  0.00696483,\n",
       "        0.02826217, -0.00501275, -0.03520845, -0.01997205, -0.02367836,\n",
       "       -0.0155376 , -0.00187721,  0.0459861 , -0.02331309,  0.02476053,\n",
       "       -0.04370702,  0.02071167,  0.02952768,  0.02044065,  0.0423478 ,\n",
       "        0.02545262,  0.01628632, -0.04094479, -0.03996222,  0.04462297,\n",
       "       -0.03908013,  0.04199353, -0.01610132,  0.01564901, -0.013139  ,\n",
       "        0.00597284,  0.00877153, -0.03182314,  0.02276621, -0.02383438,\n",
       "        0.03765985, -0.02755485, -0.02503128,  0.02739936,  0.03520251,\n",
       "        0.0371048 ,  0.03949472,  0.03401914,  0.04591072,  0.04174298,\n",
       "        0.01891393, -0.03835064,  0.01907009,  0.03154561, -0.03021329,\n",
       "       -0.04740628,  0.03474759,  0.03825137, -0.02400986, -0.01284285,\n",
       "       -0.00407534,  0.03015329,  0.02578986,  0.04487634,  0.00563987,\n",
       "        0.0126985 , -0.04686456, -0.02622954,  0.01527597,  0.01179849,\n",
       "        0.00742376,  0.04239506,  0.03950312, -0.02564234,  0.0211982 ,\n",
       "        0.01769776,  0.02090812, -0.02806363,  0.00651389,  0.02974016,\n",
       "        0.03413365,  0.04392667,  0.03663601, -0.02083234,  0.04771793,\n",
       "        0.03345467, -0.03018103,  0.0194294 ,  0.00867587, -0.02453328,\n",
       "       -0.04333834, -0.04060309, -0.00637512,  0.02077596, -0.02961885,\n",
       "       -0.03368168, -0.01126315,  0.04218874, -0.02554802,  0.02956038,\n",
       "       -0.03840526, -0.03472912,  0.0310676 ,  0.04190722, -0.03348534,\n",
       "       -0.02380203, -0.00507708, -0.02319039,  0.02813052,  0.03618817,\n",
       "        0.01993375,  0.01439602, -0.00418789, -0.02333361, -0.04701585,\n",
       "       -0.0451396 , -0.04379446, -0.0031292 , -0.04174014,  0.01285129,\n",
       "       -0.04515072, -0.01414818,  0.04047045,  0.03818984, -0.00745244,\n",
       "       -0.03374237,  0.00053776,  0.02476532,  0.0350504 ,  0.00522324,\n",
       "       -0.01621551,  0.03926425,  0.02467387], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33706f6da9b28b12de3d1d78ea840e472fd78eb772adbd1546a885ac7cd73372"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
